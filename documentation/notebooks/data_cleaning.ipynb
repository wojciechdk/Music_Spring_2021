{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Spark session.\n"
     ]
    }
   ],
   "source": [
    "from toolbox.initialize import *\n",
    "\n",
    "# spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw\n",
    "\n",
    "display_middle_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rows where activity has been deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the start time for timing.\n",
    "start_time = time.time()\n",
    "\n",
    "df_clean = (\n",
    "    df\n",
    "    .where(f.col('deleted_time').isNull()\n",
    "           | (f.col('deleted_time') == ''))\n",
    ")\n",
    "\n",
    "# Show the top rows of the resulting dataframe.\n",
    "if display_middle_results:\n",
    "    df_clean.limit(100).toPandas().head()\n",
    "\n",
    "# Show the execution time.\n",
    "print(f'Execution time: {time.time() - start_time:.5f} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping duplicates of activity id (keeping the most recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the start time for timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the time format used for the time stamp - strings in the\n",
    "# raw database.\n",
    "time_format = \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\"\n",
    "\n",
    "# Define a partitioning by activity id.\n",
    "window_id = Window.partitionBy('id')\n",
    "\n",
    "# Drop rows containing the duplicates of the activity ID.\n",
    "# Keep the activity ID with the latest timestamp-\n",
    "df_clean = (\n",
    "    df_clean\n",
    "    \n",
    "    # Convert the start time to timestamp.\n",
    "    .withColumn('start_time',\n",
    "                f.to_timestamp('start_time', time_format)) \n",
    "    \n",
    "    # Save the latest start time for each activity ID in a separate column.\n",
    "    .withColumn('latest_start_time', f.max('start_time').over(window_id))\n",
    "    \n",
    "    # Keep only rows with the latest start time for the given activity ID.\n",
    "    .where(f.col('start_time') == f.col('latest_start_time'))\n",
    "        \n",
    "    # Keep only the first occurrence of each activity ID.\n",
    "    .dropDuplicates(['id'])\n",
    "    \n",
    "    # Delete the column containing the lates start time.\n",
    "    .drop('latest_start_time')\n",
    ")\n",
    "\n",
    "# Show the top rows of the resulting dataframe.\n",
    "if display_middle_results:\n",
    "    df_clean.limit(100).toPandas().head()\n",
    "    \n",
    "# Print the execution time.\n",
    "print(f'Execution time: {time.time() - start_time:.5f} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploding the columns `devices` and `tracks` and flattening the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore the column devices and tracks\n",
    "# and flatten the schema.\n",
    "df_clean = t.format_dataframe(df_clean)\n",
    "\n",
    "# Show the top rows of the resulting dataframe.\n",
    "if display_middle_results:\n",
    "    df_clean.limit(100).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing start and end time with start time and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save the start time for timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Define the time format used for the time stamp - strings in the\n",
    "# raw database.\n",
    "time_format = \"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\"\n",
    "\n",
    "df_clean = (\n",
    "    df_clean\n",
    "#     .withColumn('start_time',\n",
    "#                 f.to_timestamp('start_time', time_format))\n",
    "    .withColumn('end_time',\n",
    "                f.to_timestamp('end_time', time_format))\n",
    "    .withColumn('activity_duration',\n",
    "                f.col('end_time').cast(LongType()) \n",
    "                - f.col('start_time').cast(LongType()))   \n",
    "    .withColumn('tracks_start_time',\n",
    "                f.to_timestamp('tracks_start_time', time_format))\n",
    "    .withColumn('tracks_end_time',\n",
    "                f.to_timestamp('tracks_end_time', time_format))\n",
    "    .withColumn('track_duration',\n",
    "                f.col('tracks_end_time').cast(LongType()) \n",
    "                - f.col('tracks_start_time').cast(LongType()))\n",
    "    .drop('end_time')\n",
    "    .drop('tracks_end_time')\n",
    ")\n",
    "\n",
    "# Show the top rows of the resulting dataframe.\n",
    "if display_middle_results:\n",
    "    df_clean.limit(100).toPandas().head()\n",
    "    \n",
    "# Print the execution time.\n",
    "print(f'Execution time: {time.time() - start_time:.5f} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Track ID and Track URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't decide whether it's a good idea or not. `tracks_id` seems to be a path to a file in the Sony system, which I can't see give any useful information, maybe aside of comparing the track properties of multiple rows with the same track id to look for inconsitencies. I will be dropping the merge for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_clean = (\n",
    "#     df_clean\n",
    "#     .withColumn('track_id',\n",
    "#                 f.concat(f.col('tracks_id'), \n",
    "#                          f.col('tracks_uri')))\n",
    "#     .drop('tracks_id')\n",
    "#     .drop('tracks_uri')\n",
    "# )\n",
    "\n",
    "# df_clean.limit(3).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop redundand columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the columns:\n",
    "\n",
    "* `deleted_time`\n",
    "* `devices_type`\n",
    "* `yearmonth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean = (\n",
    "    df_clean\n",
    "    .drop('deleted_time')\n",
    "    .drop('devices_type')\n",
    "    .drop('yearmonth')\n",
    ")\n",
    "\n",
    "# Show the top rows of the resulting dataframe.\n",
    "if display_middle_results:\n",
    "    df_clean.limit(100).toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename and organize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df_clean = (\n",
    "    df_clean\n",
    "    \n",
    "    # Give columns meaningful names.\n",
    "    .withColumnRenamed('id', 'activity_id')\n",
    "    .withColumnRenamed('useruuid', 'user_id')\n",
    "    .withColumnRenamed('start_time', 'activity_start_time')\n",
    "    .withColumnRenamed('devices_name', 'device_name')\n",
    "    .withColumnRenamed('devices_id', 'device_id')\n",
    "    .withColumnRenamed('tracks_start_time', 'track_start_time')\n",
    "    .withColumnRenamed('tracks_artist', 'track_artist')\n",
    "    .withColumnRenamed('tracks_album', 'track_album')\n",
    "    .withColumnRenamed('tracks_title', 'track_title')\n",
    "    .withColumnRenamed('tracks_player', 'track_player')\n",
    "    .withColumnRenamed('tracks_id', 'track_id')\n",
    "    .withColumnRenamed('tracks_uri', 'track_uri')\n",
    "    \n",
    "    # Place the columns belonging to the same group next to each other.\n",
    "    .select('user_id',\n",
    "            'activity_id', 'activity_start_time', 'activity_duration',\n",
    "            'device_id', 'device_name',\n",
    "            'track_artist', 'track_title', 'track_album',\n",
    "            'track_player', 'track_start_time', 'track_duration',\n",
    "            'track_id', 'track_uri')\n",
    "    \n",
    "    # Sort the data.\n",
    "    .orderBy(f.asc('user_id'),\n",
    "             f.asc('activity_start_time'))\n",
    ")\n",
    "\n",
    "# Show the top rows of the resulting dataframe.\n",
    "df_clean.limit(100).toPandas().head()\n",
    "    \n",
    "# Print the execution time.\n",
    "print(f'Execution time: {time.time() - start_time:.5f} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "# Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.spark.save_dataframe_to_parquet(\n",
    "    df_clean, Config.Path.project_data_root / 'df_1E6_clean.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "344.85px",
    "left": "1553px",
    "right": "20px",
    "top": "120px",
    "width": "347px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
